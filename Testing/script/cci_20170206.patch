From efd5bba21937e3555e9e320f5494de281984ad28 Mon Sep 17 00:00:00 2001
From: Scott Atchley <atchleyes@ornl.gov>
Date: Wed, 29 Jun 2016 15:01:55 -0400
Subject: [PATCH] sm: set the device's pid when not using config

Fix suggested by John Jenkins <jenkins@mcs.anl.gov>

sm: fix leaks when closing a conn

Ignore *dSYM, *patch, *txt

tests: add connect_test

This test will stress connection setup. Parameters include number of
endpoints, number of threads per endpoint, number of open connections
per endpoint. It will run until N connections are processed or for T
seconds.

This code brings up the test state, the control endpoint, opens a
connection between the control endpoints, and creates the threads (which
promptly exit).

Need to implement the test connections.

tcp: only read from the pipe once

when reaping an event

tcp: convert to array of pollfds per endpoint

Convert TCP connection pfd pointer which points to a pollfd in the above
array. Maintain a bitmap of available pollfd slots in the array. Have
each connection cache its index in the array.

tcp: implement blocking mode without polling

tcp: #define _GNU_SOURCE

for ffsll() on Linux

tcp: don't leak tep->fds

Reported by Jeff Oliver <jeffrey.v.olivier@intel.com>

tcp: free tep->fd_bits as well

Also, if realloc() succeeds and uses a new buffer, free the old buffer.

tcp: no need to free original buffer

if realloc() succeeds.

sock: reduce minimum MSS to 1000 bytes less header

sm: do not queue blocking send

Also, put the tx if silent or blocking.
Also, if CMA fails, warn once.

verbs: improve connection handling

sm: fix race condition during init

When multiple processes are starting up on the same node, they race to
create the device's path. Handle the errors properly.

Reported by John Jenkins <jenkins@mcs.anl.gov>

tcp: don't leak the RMA completion MSG

Reported by Preethika Kasu <preethika.kasu@gmail.com>

verbs: return correct error if ibv_post_send fails

sm: do not dereference conn before NULL check

in sm_free_conn(). We already checked for NULL but we dereferenced it
before checking. Check before dereferencing.

Reported by Ross Miller <rgmiller@ornl.gov>

sm: print remote length

If the RMA length + remote offset exceeds the remote registration's
length, print the remote registration length, not the local length.

Reported by Ross Miller <rgmiller@ornl.gov>

tcp: close socket and do not open two

When connecting, only open one socket. We were opening two and we leaked
the first one.

Close the socket before calling release_pollfd() because it sets the fd
to -1.

Bug reported by Wenzhao Zhang <wzhang27@ncsu.edu>

tcp: fix race between during accept

Move the connection lock to before sending the connection reply to
avoid the race with the client's conn ack.

Avoid namespace conflicts for initialized

Add cci_ prefix.

Reported by and suggested fix by Wenzhao Zhang <wzhang27@ncsu.edu>

tcp: don't leak rx during accept

tcp: revert c37fa323fe

The rx is not leaked. It is returned when the caller returns the
CONNECT_REQUEST event.

Reported by Chuck Cranor <chuck@ece.cmu.edu>
---
 .gitignore                            |   4 +
 include/cci_lib_types.h               |   4 +-
 src/api/finalize.c                    |   8 +-
 src/api/init.c                        |  10 +-
 src/plugins/ctp/sm/ctp_sm_api.c       |  88 +++-
 src/plugins/ctp/sock/ctp_sock.h       |   2 +-
 src/plugins/ctp/tcp/ctp_tcp.h         |  24 +-
 src/plugins/ctp/tcp/ctp_tcp_api.c     | 250 ++++++++---
 src/plugins/ctp/verbs/ctp_verbs.h     |   4 +-
 src/plugins/ctp/verbs/ctp_verbs_api.c | 150 +++++--
 src/tests/connect_test.c              | 780 ++++++++++++++++++++++++++++++++++
 11 files changed, 1179 insertions(+), 145 deletions(-)
 create mode 100644 src/tests/connect_test.c

diff --git a/include/cci_lib_types.h b/include/cci_lib_types.h
index 493d27e..501f96d 100644
--- a/include/cci_lib_types.h
+++ b/include/cci_lib_types.h
@@ -186,8 +186,8 @@ typedef struct cci__globals {
 	uint32_t flags;
 } cci__globals_t;
 
-extern pthread_mutex_t init_lock; /*! Protects initialized and globals during cci_init() and cci_finalize() */
-extern int initialized; /*! How many times cci_init() was called minus how many times cci_finalize() was called */
+extern pthread_mutex_t init_lock; /*! Protects cci_initialized and globals during cci_init() and cci_finalize() */
+extern int cci_initialized; /*! How many times cci_init() was called minus how many times cci_finalize() was called */
 extern cci__globals_t *globals;
 
 /*! Obtain the private struct from the public struct
diff --git a/src/api/finalize.c b/src/api/finalize.c
index e061866..7fbe616 100644
--- a/src/api/finalize.c
+++ b/src/api/finalize.c
@@ -28,14 +28,14 @@ int cci_finalize(void)
 
 	pthread_mutex_lock(&init_lock);
 
-	if (!initialized) {
-		/* not initialized */
+	if (!cci_initialized) {
+		/* not cci_initialized */
 		ret = CCI_ERROR;
 		goto out;
 	}
 
-	initialized--;
-	if (initialized > 0) {
+	cci_initialized--;
+	if (cci_initialized > 0) {
 		/* no-op, return SUCCESS */
 		goto out;
 	}
diff --git a/src/api/init.c b/src/api/init.c
index 9c7c53a..b2a893e 100644
--- a/src/api/init.c
+++ b/src/api/init.c
@@ -46,7 +46,7 @@
 
 int cci__debug = CCI_DB_DFLT;
 cci__globals_t *globals = NULL;
-int initialized = 0;
+int cci_initialized = 0;
 static pthread_once_t once = PTHREAD_ONCE_INIT;
 pthread_mutex_t init_lock;
 
@@ -572,7 +572,7 @@ int cci_init(uint32_t abi_ver, uint32_t flags, uint32_t * caps)
 	pthread_once(&once, cci_lock_init);
 	pthread_mutex_lock(&init_lock);
 
-	if (0 == initialized) {
+	if (0 == cci_initialized) {
 		cci__dev_t *dev;
 		char *str;
 
@@ -666,13 +666,13 @@ int cci_init(uint32_t abi_ver, uint32_t flags, uint32_t * caps)
 		pthread_mutex_unlock(&globals->lock);
 
 		/* success */
-		initialized++;
+		cci_initialized++;
 
 	} else {
-		/* already initialized */
+		/* already cci_initialized */
 		if (flags == globals->flags) {
 			/* same parameters, no-op */
-			initialized++;
+			cci_initialized++;
 		} else {
 			/* TODO */
 			/* if different, can we accomodate new params?
diff --git a/src/plugins/ctp/sm/ctp_sm_api.c b/src/plugins/ctp/sm/ctp_sm_api.c
index 91ce369..7cdfb36 100644
--- a/src/plugins/ctp/sm/ctp_sm_api.c
+++ b/src/plugins/ctp/sm/ctp_sm_api.c
@@ -211,6 +211,7 @@ sm_create_path(const char *path)
 		if (ret) {
 			if (ret == EEXIST) {
 				/* it exists */
+				ret = 0;
 			} else if (ret == ENOENT) {
 				/* No, try to create it */
 				ret = mkdir(new, 0755);
@@ -220,6 +221,8 @@ sm_create_path(const char *path)
 							strerror(errno));
 					ret = CCI_ERROR;
 					goto out;
+				} else {
+					ret = 0;
 				}
 			} else {
 				/* No, but we got another error.
@@ -320,6 +323,7 @@ static int ctp_sm_init(cci_plugin_ctp_t *plugin, uint32_t abi_ver, uint32_t flag
 		if (ret)
 			goto out;
 
+		sdev->pid = pid;
 		sdev->id = 0;
 
 		device->up = 1;
@@ -622,12 +626,7 @@ static int ctp_sm_finalize(cci_plugin_ctp_t * plugin)
 		if (!strcmp(dev->device.transport, "sm")) {
 			if (dev->priv) {
 				sm_dev_t *sdev = dev->priv;
-				int ret = 0;
 
-				ret = rmdir(sdev->path);
-				if (ret)
-					debug(CCI_DB_INFO, "%s: rmdir(%s) failed with %s",
-						__func__, sdev->path, strerror(errno));
 				free(sdev->path);
 				free(sdev->ids);
 			}
@@ -1323,15 +1322,37 @@ static void
 sm_free_conn(cci__conn_t *conn)
 {
 	int ret = 0;
-	cci_connection_t *connection = &conn->connection;
-	cci__ep_t *ep = container_of(connection->endpoint, cci__ep_t, endpoint);
-	sm_ep_t *sep = ep->priv;
-	sm_conn_t *sconn = conn->priv;
+	cci_connection_t *connection = NULL;
+	cci__ep_t *ep = NULL;
+	sm_ep_t *sep = NULL;
+	sm_conn_t *sconn = NULL;
 
 	if (!conn)
 		return;
 
+	connection = &conn->connection;
+	ep = container_of(connection->endpoint, cci__ep_t, endpoint);
+	sep = ep->priv;
+	sconn = conn->priv;
+
 	if (sconn) {
+		int len = sizeof(*sconn->tx);
+
+		if (sconn->fifo != 0)
+			close(sconn->fifo);
+
+		if (sconn->mmap)
+			munmap(sconn->mmap, len);
+		if (sconn->peer_mmap)
+			munmap(sconn->peer_mmap, len);
+
+		len = sizeof(*sconn->rma);
+
+		if (sconn->rma_mmap)
+			munmap(sconn->rma_mmap, len);
+		if (sconn->peer_rma_mmap)
+			munmap(sconn->peer_rma_mmap, len);
+
 		free(sconn->name);
 		if (sconn->id != -1) {
 			ret = pthread_rwlock_wrlock(&sep->conns_lock);
@@ -1351,11 +1372,28 @@ sm_free_conn(cci__conn_t *conn)
 						tdelete(sconn, &sep->conns,
 								sm_compare_conns);
 					}
+					else {
+						debug(CCI_DB_WARN, "%s: tmp %p != sconn %p",
+								__func__,
+								(void*)tmp,
+								(void*)sconn);
+					}
+				}
+				else {
+					debug(CCI_DB_WARN, "%s: sconn %p not found",
+							__func__, (void*)sconn);
 				}
 				pthread_rwlock_unlock(&sep->conns_lock);
 			}
 			sm_put_conn_id(sconn);
 		}
+		else {
+			debug(CCI_DB_WARN, "%s: sconn %p id == -1",
+					__func__, (void*)sconn);
+		}
+		if (sconn->params)
+			free(sconn->params->data_ptr);
+		free(sconn->params);
 		free(sconn->rxs);
 		free(sconn->txs);
 		free(sconn);
@@ -1832,13 +1870,8 @@ static int ctp_sm_connect(cci_endpoint_t * endpoint, const char *server_uri,
 	debug(CCI_DB_CONN, "%s: connecting to %s", __func__, server_uri);
 
     out:
-	if (ret) {
-		if (params) {
-			free(params->data_ptr);
-			free(params);
-		}
+	if (ret)
 		sm_free_conn(conn);
-	}
 
 	CCI_EXIT;
 	return ret;
@@ -1954,9 +1987,7 @@ sm_handle_connect(cci__ep_t *ep, const char *path, void *buffer, int len)
 		debug(CCI_DB_CONN, "%s: unable to service connect request from "
 			"%s (%s) - dropping message", __func__, uri,
 			cci_strerror(&ep->endpoint, ret));
-		if (conn) {
-			sm_free_conn(conn);
-		}
+		sm_free_conn(conn);
 		if (rx) {
 			free((void*)rx->event.request.data_ptr);
 			free(rx);
@@ -2036,6 +2067,7 @@ sm_handle_connect_reply(cci__ep_t *ep, void *buffer)
 
 	free(params->data_ptr);
 	free(params);
+	sconn->params = NULL;
 
 	evt->event.type = CCI_EVENT_CONNECT;
 	evt->event.connect.context = conn->connection.context;
@@ -2974,11 +3006,13 @@ static int ctp_sm_send(cci_connection_t * connection,
 
 	sm_conn_notify(ep, conn);
 
-	if (!(flags & CCI_FLAG_SILENT)) {
+	if (!(flags & CCI_FLAG_SILENT) && !(flags & CCI_FLAG_BLOCKING)) {
 		pthread_mutex_lock(&ep->lock);
 		TAILQ_INSERT_TAIL(&ep->evts, evt, entry);
 		sm_ep_notify(ep);
 		pthread_mutex_unlock(&ep->lock);
+	} else {
+		sm_put_tx(evt);
 	}
 
     out:
@@ -3171,7 +3205,8 @@ static int ctp_sm_rma(cci_connection_t * connection,
 		debug(CCI_DB_MSG,
 			"%s: RMA length + offset exceeds remote registered length "
 			"(%"PRIu64" + %"PRIu64" > %"PRIu64")",
-			__func__, data_len, local_offset, sh->len);
+			__func__, data_len, local_offset,
+			remote_handle->stuff[2]);
 		ret = CCI_EINVAL;
 		goto out;
 	}
@@ -3258,10 +3293,21 @@ static int ctp_sm_rma(cci_connection_t * connection,
 				&local, 1, &remote, 1, 0);
 		}
 		if (rc != (ssize_t)data_len) {
-			ret = errno;
+			static int once = 0;
+
+			if (rc != -1) {
+				/* partial transfer - bad iovec segment */
+				ret = EFAULT;
+			} else {
+				ret = errno;
+			}
 			debug(CCI_DB_MSG, "%s: process_vm_%s() failed with %s",
 				__func__, flags & CCI_FLAG_WRITE ? "write" : "read",
 				strerror(ret));
+			if (once == 0 && ret == EPERM) {
+				debug(CCI_DB_WARN, "%s: process_vm_%s() failed because it cannot trace another process. See https://www.kernel.org/doc/Documentation/security/Yama.txt for more details.", __func__, flags & CCI_FLAG_WRITE ? "write" : "read");
+				once++;
+			}
 			goto out;
 		}
 
diff --git a/src/plugins/ctp/sock/ctp_sock.h b/src/plugins/ctp/sock/ctp_sock.h
index 3f0a386..44c9c2a 100644
--- a/src/plugins/ctp/sock/ctp_sock.h
+++ b/src/plugins/ctp/sock/ctp_sock.h
@@ -30,7 +30,7 @@ BEGIN_C_DECLS
 #define SOCK_MAX_HDRS           (SOCK_MAX_HDR_SIZE + 20 + 8)	/* IP + UDP */
 #define SOCK_DEFAULT_MSS        (SOCK_UDP_MAX - SOCK_MAX_HDR_SIZE)	/* assume jumbo frames */
 #define SOCK_DEFAULT_RMA_MSS    (SOCK_DEFAULT_MSS - 20)
-#define SOCK_MIN_MSS            (1500 - SOCK_MAX_HDR_SIZE)
+#define SOCK_MIN_MSS            (1000 - SOCK_MAX_HDR_SIZE)
 #define SOCK_MAX_SACK           (4)	/* pairs of start/end acks */
 #define SOCK_ACK_DELAY          (1)	/* send an ack after every Nth send */
 #define SOCK_EP_TX_TIMEOUT_SEC  (64)	/* seconds for now */
diff --git a/src/plugins/ctp/tcp/ctp_tcp.h b/src/plugins/ctp/tcp/ctp_tcp.h
index 604185c..e552123 100644
--- a/src/plugins/ctp/tcp/ctp_tcp.h
+++ b/src/plugins/ctp/tcp/ctp_tcp.h
@@ -695,9 +695,18 @@ struct tcp_ep {
 	/*! Last conn polled */
 	tcp_conn_t *poll_conn;
 
+	/*! Number of bitmap 64-bit blocks */
+	int blocks;
+
+	/*! Poll FD bitmap */
+	uint64_t *fd_bits;
+
 	/*! Number of pollfds */
 	nfds_t nfds;
 
+	/*! Arrary of poll fds - multiples of 64 */
+	struct pollfd *fds;
+
 	/*! TX common buffer */
 	void *tx_buf;
 
@@ -802,7 +811,7 @@ struct tcp_conn {
 	int refcnt;
 
 	/*! poll fd */
-	struct pollfd pfd;
+	struct pollfd *pfd;
 
 	/*! partial receive */
 	tcp_rx_t *rx;
@@ -813,6 +822,9 @@ struct tcp_conn {
 	/*! Is this the endpoint's listening socket? */
 	int is_listener;
 
+	/*! Poll fd index */
+	int idx;
+
 	/*! Entry to hang on tcp_ep->conns */
 	 TAILQ_ENTRY(tcp_conn) entry;
 
@@ -846,16 +858,6 @@ struct tcp_dev {
 	uint32_t bufsize;
 };
 
-typedef enum tcp_fd_type {
-	TCP_FD_UNUSED = 0,
-	TCP_FD_EP
-} tcp_fd_type_t;
-
-typedef struct tcp_fd_idx {
-	tcp_fd_type_t type;
-	cci__ep_t *ep;
-} tcp_fd_idx_t;
-
 struct tcp_globals {
 	/*! Mutex */
 	pthread_mutex_t lock;
diff --git a/src/plugins/ctp/tcp/ctp_tcp_api.c b/src/plugins/ctp/tcp/ctp_tcp_api.c
index ecba822..a60ff32 100644
--- a/src/plugins/ctp/tcp/ctp_tcp_api.c
+++ b/src/plugins/ctp/tcp/ctp_tcp_api.c
@@ -10,6 +10,7 @@
  *
  */
 
+#define _GNU_SOURCE
 #include "cci/private_config.h"
 
 #include <stdio.h>
@@ -29,6 +30,7 @@
 #include <net/if.h>
 #include <ifaddrs.h>
 #endif
+#include <strings.h>
 
 #include "cci.h"
 #include "cci_lib_types.h"
@@ -547,6 +549,9 @@ queue_conn(cci__ep_t *ep, cci__conn_t *conn);
 static void
 conn_decref(cci__ep_t *ep, cci__conn_t *conn);
 
+static void
+release_pollfd(cci__ep_t *ep, tcp_conn_t *tconn);
+
 static int ctp_tcp_create_endpoint_at(cci_device_t * device,
 				      const char * service,
 				      int flags,
@@ -597,6 +602,20 @@ static int ctp_tcp_create_endpoint_at(cci_device_t * device,
 
 	TAILQ_INIT(&tep->conns);
 
+	tep->blocks = 1;
+	tep->fd_bits = malloc(sizeof(*tep->fd_bits));
+	if (!tep->fd_bits) {
+		ret = CCI_ENOMEM;
+		goto out;
+	}
+	memset(tep->fd_bits, -1, sizeof(*tep->fd_bits));
+
+	tep->fds = calloc(64, sizeof(*tep->fds));
+	if (!tep->fds) {
+		ret = CCI_ENOMEM;
+		goto out;
+	}
+
 	TAILQ_INIT(&tep->idle_txs);
 	TAILQ_INIT(&tep->idle_rxs);
 	TAILQ_INIT(&tep->handles);
@@ -652,7 +671,7 @@ static int ctp_tcp_create_endpoint_at(cci_device_t * device,
 	tconn = conn->priv;
 	tconn->status = TCP_CONN_PASSIVE1;
 	tconn->is_listener = 1;
-	tconn->pfd.events = POLLIN;
+	tconn->pfd->events = POLLIN;
 	queue_conn(ep, conn);
 
 	tep->tx_buf = calloc(1, ep->tx_buf_cnt * ep->buffer_len);
@@ -740,9 +759,9 @@ out:
 			pthread_mutex_lock(&ep->lock);
 			TAILQ_REMOVE(&tep->conns, tconn, entry);
 			pthread_mutex_unlock(&ep->lock);
-			if (tconn->pfd.fd) {
-				close(tconn->pfd.fd);
-				tconn->pfd.fd = 0;
+			if (tconn->pfd->fd) {
+				close(tconn->pfd->fd);
+				release_pollfd(ep, tconn);
 			}
 		}
 		free((char*)conn->uri);
@@ -757,6 +776,9 @@ out:
 		free(tep->rxs);
 		free(tep->rx_buf);
 
+		free(tep->fds);
+		free(tep->fd_bits);
+
 		if (sock)
 			tcp_close_socket(sock);
 		free(tep);
@@ -799,9 +821,9 @@ tcp_conn_set_closed(cci__ep_t *ep, cci__conn_t *conn)
 	if (tconn->status == TCP_CONN_READY) {
 		if (tep->poll_conn == tconn)
 			tep->poll_conn = NULL;
-		if (tconn->pfd.fd) {
-			close(tconn->pfd.fd);
-			tconn->pfd.fd = 0;
+		if (tconn->pfd->fd) {
+			close(tconn->pfd->fd);
+			release_pollfd(ep, tconn);
 		}
 		/* TODO complete queued and pending sends */
 	}
@@ -821,9 +843,9 @@ tcp_conn_set_closing_locked(cci__ep_t *ep, cci__conn_t *conn)
 	tcp_conn_t *tconn = conn->priv;
 
 	if (tconn->status > TCP_CONN_INIT) {
-		if (tconn->pfd.fd) {
-			close(tconn->pfd.fd);
-			tconn->pfd.fd = 0;
+		if (tconn->pfd->fd) {
+			close(tconn->pfd->fd);
+			release_pollfd(ep, tconn);
 		}
 		tconn->status = TCP_CONN_CLOSING;
 		/* TODO complete queued and pending sends */
@@ -911,6 +933,9 @@ static int ctp_tcp_destroy_endpoint(cci_endpoint_t * endpoint)
 			free(handle);
 		}
 
+		free(tep->fds);
+		free(tep->fd_bits);
+
 		if (tep->pipe[0] != -1)
 			close(tep->pipe[0]);
 		if (tep->pipe[1] != -1)
@@ -1083,10 +1108,12 @@ static int ctp_tcp_accept(cci_event_t *event, const void *context)
 	if (!tx) {
 		/* TODO send reject */
 		/* TODO tep->nfds-- */
+		debug(CCI_DB_CONN, "%s: unable to get tx for conn %p (%s)",
+				__func__, (void*) conn, conn->uri);
 
-		if (tconn->pfd.fd) {
-			close(tconn->pfd.fd);
-			tconn->pfd.fd = 0;
+		if (tconn->pfd->fd) {
+			close(tconn->pfd->fd);
+			release_pollfd(ep, tconn);
 		}
 
 		pthread_mutex_lock(&ep->lock);
@@ -1131,12 +1158,12 @@ static int ctp_tcp_accept(cci_event_t *event, const void *context)
 
 	tx->len = sizeof(*hdr) + sizeof(*hs);
 
+	pthread_mutex_lock(&tconn->lock);
 	tx->state = TCP_TX_PENDING;
-	tcp_sendto(tconn->pfd.fd, tx->buffer, tx->len, NULL, 0, &offset);
+	tcp_sendto(tconn->pfd->fd, tx->buffer, tx->len, NULL, 0, &offset);
 
 	assert((uint32_t)offset == tx->len);
 
-	pthread_mutex_lock(&tconn->lock);
 	TAILQ_INSERT_HEAD(&tconn->pending, &tx->evt, entry);
 	pthread_mutex_unlock(&tconn->lock);
 
@@ -1188,7 +1215,7 @@ static int ctp_tcp_reject(cci_event_t *event)
 	memset(&reject, 0, sizeof(reject));
 	tcp_pack_conn_reply(&reject, CCI_ECONNREFUSED, b);
 
-	tcp_sendto(tconn->pfd.fd, &reject, sizeof(reject),
+	tcp_sendto(tconn->pfd->fd, &reject, sizeof(reject),
 			NULL, 0, &offset);
 
 	memset(name, 0, sizeof(name));
@@ -1253,6 +1280,89 @@ static int tcp_getaddrinfo(const char *uri, in_addr_t * in, uint16_t * port)
 	return CCI_SUCCESS;
 }
 
+/* This function will loop until it can successfully assign a pollfd.
+ * If either realloc() fails, it tries again. In a low memory state,
+ * this may try forever.
+ */
+static void
+assign_pollfd(cci__ep_t *ep, tcp_conn_t *tconn)
+{
+	int i = 0;
+	int idx = -1;
+	tcp_ep_t *tep = ep->priv;
+
+	pthread_mutex_lock(&ep->lock);
+
+    again:
+	for (i = 0; i < tep->blocks; i++) {
+		uint64_t *bits = &tep->fd_bits[i];
+
+		if (!(*bits))
+			continue;
+
+		idx = ffsll(*bits) - 1;
+
+		*bits = *bits & ~((uint64_t)1 << idx);
+		idx += i * 64;
+	}
+
+	if (idx == -1) {
+		uint64_t *tmp = NULL;
+		struct pollfd *fds = NULL;
+
+		tep->blocks++;
+
+		tmp = realloc(tep->fd_bits, tep->blocks * sizeof(*tep->fd_bits));
+		if (!tmp)
+			goto again; /* will retry */
+
+		tep->fd_bits = tmp;
+		tmp = &tep->fd_bits[tep->blocks - 1];
+		memset(tmp, -1, sizeof(*tmp));
+
+		fds = realloc(tep->fds, tep->blocks * sizeof(*tep->fds) * 64);
+		if (!fds)
+			goto again; /* will retry */
+
+		tep->fds = fds;
+		fds = (void*)((uintptr_t)tep->fds +
+				(uintptr_t)((tep->blocks - 1) * sizeof(*tep->fds)));
+		memset(fds, 0, sizeof(tep->fds) * 64);
+
+		goto again;
+	}
+
+	if (tep->nfds < (nfds_t) idx + 1)
+		tep->nfds = (nfds_t) idx + 1;
+
+	pthread_mutex_unlock(&ep->lock);
+
+	tconn->idx = idx;
+	tconn->pfd = &tep->fds[idx];
+
+	return;
+}
+
+static void
+release_pollfd(cci__ep_t *ep, tcp_conn_t *tconn)
+{
+	int i = 0, idx = 0;
+	tcp_ep_t *tep = ep->priv;
+	uint64_t *bits = NULL;
+
+	i = tconn->idx / 64;
+	idx = tconn->idx % 64;
+
+	bits = &tep->fd_bits[i];
+	*bits = *bits | ((uint64_t)1 << idx);
+
+	tconn->pfd->fd = -1;
+	tconn->pfd->events = 0;
+	tconn->idx = -1;
+
+	return;
+}
+
 static inline int
 tcp_new_conn(cci__ep_t *ep, struct sockaddr_in sin, int fd, cci__conn_t **connp)
 {
@@ -1282,7 +1392,10 @@ tcp_new_conn(cci__ep_t *ep, struct sockaddr_in sin, int fd, cci__conn_t **connp)
 	tconn = conn->priv;
 	tconn->conn = conn;
 	tconn->refcnt = 1; /* one for the caller */
-	tconn->pfd.fd = fd;
+
+	assign_pollfd(ep, tconn);
+
+	tconn->pfd->fd = fd;
 	if (fd != -1)
 		tconn->status = TCP_CONN_ACTIVE1;
 	else
@@ -1295,13 +1408,14 @@ tcp_new_conn(cci__ep_t *ep, struct sockaddr_in sin, int fd, cci__conn_t **connp)
 
 	ret = pthread_mutex_init(&tconn->lock, &attr);
 	if (ret)
-		goto out_with_tconn;
+		goto out_with_pollfd;
 
 	*connp = conn;
 
 	return ret;
 
-out_with_tconn:
+out_with_pollfd:
+	release_pollfd(ep, tconn);
 	free(tconn);
 out_with_conn:
 	free(conn);
@@ -1316,11 +1430,11 @@ tcp_monitor_fd(cci__ep_t *ep, cci__conn_t *conn, int events)
 	tcp_dev_t *tdev = dev->priv;
 	tcp_conn_t *tconn = conn->priv;
 
-	ret = tcp_set_nonblocking(tconn->pfd.fd);
+	ret = tcp_set_nonblocking(tconn->pfd->fd);
 	if (ret)
 		goto out;
 
-	ret = setsockopt(tconn->pfd.fd, IPPROTO_TCP, TCP_NODELAY, &one, sizeof(one));
+	ret = setsockopt(tconn->pfd->fd, IPPROTO_TCP, TCP_NODELAY, &one, sizeof(one));
 	if (ret)
 		goto out;
 
@@ -1331,11 +1445,11 @@ tcp_monitor_fd(cci__ep_t *ep, cci__conn_t *conn, int events)
 		debug(CCI_DB_CONN, "%s: setting socket buffer sizes to %u",
 			__func__, bufsize);
 
-		ret = setsockopt(tconn->pfd.fd, SOL_SOCKET, SO_SNDBUF, &bufsize, opt_len);
+		ret = setsockopt(tconn->pfd->fd, SOL_SOCKET, SO_SNDBUF, &bufsize, opt_len);
 		if (ret) debug(CCI_DB_EP, "%s: unable to set SO_SNDBUF (%s)",
 				__func__, strerror(errno));
 
-		ret = setsockopt(tconn->pfd.fd, SOL_SOCKET, SO_RCVBUF, &bufsize, opt_len);
+		ret = setsockopt(tconn->pfd->fd, SOL_SOCKET, SO_RCVBUF, &bufsize, opt_len);
 		if (ret) debug(CCI_DB_EP, "%s: unable to set SO_RCVBUF (%s)",
 				__func__, strerror(errno));
 
@@ -1343,7 +1457,7 @@ tcp_monitor_fd(cci__ep_t *ep, cci__conn_t *conn, int events)
 	}
 
 	pthread_mutex_lock(&ep->lock);
-	tconn->pfd.events = events;
+	tconn->pfd->events = events;
 	pthread_mutex_unlock(&ep->lock);
 
 out:
@@ -1476,15 +1590,6 @@ static int ctp_tcp_connect(cci_endpoint_t * endpoint, const char *server_uri,
 	tx->len += data_len;
 	assert(tx->len <= ep->buffer_len);
 
-	/* start connect now */
-	ret = socket(PF_INET, SOCK_STREAM, 0);
-	if (ret == -1) {
-		ret = errno;
-		debug(CCI_DB_CONN, "%s: socket returned %s", __func__, strerror(ret));
-		goto out;
-	}
-	tconn->pfd.fd = ret;
-
 	/* we will have to check for POLLOUT to determine when
 	 * the connect completed
 	 */
@@ -1503,7 +1608,7 @@ static int ctp_tcp_connect(cci_endpoint_t * endpoint, const char *server_uri,
 
 again:
 	/* ok, initiate connect()... */
-	ret = connect(tconn->pfd.fd, (struct sockaddr *)&sin, slen);
+	ret = connect(tconn->pfd->fd, (struct sockaddr *)&sin, slen);
 	if (ret) {
 		ret = errno;
 		if (ret == EINTR) {
@@ -1520,7 +1625,7 @@ again:
 	} else {
 		/* TODO connect completed, send CONN_REQUEST */
 		debug(CCI_DB_CONN, "%s: connect() completed", __func__);
-		tconn->pfd.events = POLLIN | POLLOUT;
+		tconn->pfd->events = POLLIN | POLLOUT;
 	}
 
 	conn_decref(ep, conn); /* drop our reference */
@@ -1537,10 +1642,6 @@ out:
 		pthread_mutex_unlock(&ep->lock);
 
 		free((char *)conn->uri);
-#if CCI_DEBUG
-		memset(tconn, 0xFF, sizeof(*tconn));
-		memset(conn, 0xFF, sizeof(*conn));
-#endif
 		free(conn->priv);
 		free(conn);
 	}
@@ -1708,12 +1809,15 @@ static int ctp_tcp_get_event(cci_endpoint_t * endpoint, cci_event_t ** const eve
 	pthread_mutex_unlock(&ep->lock);
 
 	/* drain fd so that they can block again */
-	if (TCP_CONN_IS_BLOCKING(tep)) {
+	if (ev && TCP_CONN_IS_BLOCKING(tep)) {
 		char a[1];
+#if 0
 		do {
 			/* Nothing explicit to do here */
 		} while (tcp_event_queue_is_empty (ep) &&
 		         read (tep->pipe[0], a, sizeof(a)) != sizeof (a));
+#endif
+		read (tep->pipe[0], a, sizeof(a));
 	}
 
 	*event = &ev->event;
@@ -1839,7 +1943,7 @@ tcp_progress_conn_sends(cci__conn_t *conn)
 			"offset %"PRIuPTR" tx %u", __func__, (void*)tx->buffer,
 			tx->len, (void*)tx->rma_ptr, tx->rma_len, tx->offset, tx->id);
 
-		ret = tcp_sendto(tconn->pfd.fd, tx->buffer, tx->len,
+		ret = tcp_sendto(tconn->pfd->fd, tx->buffer, tx->len,
 				tx->rma_ptr, tx->rma_len, &tx->offset);
 		if (ret) {
 			if (ret == EAGAIN || ret == EINTR) {
@@ -1910,7 +2014,7 @@ tcp_queue_tx(tcp_ep_t *tep, tcp_conn_t *tconn, cci__evt_t *evt)
 {
 	pthread_mutex_lock(&tconn->lock);
 	TAILQ_INSERT_TAIL(&tconn->queued, evt, entry);
-	tconn->pfd.events = POLLIN | POLLOUT;
+	tconn->pfd->events = POLLIN | POLLOUT;
 	pthread_mutex_unlock(&tconn->lock);
 }
 
@@ -2028,7 +2132,7 @@ static int tcp_send_common(cci_connection_t * connection,
 	/* if unreliable, try to send */
 	if (!is_reliable) {
     again:
-		ret = tcp_sendto(tconn->pfd.fd, tx->buffer, tx->len, tx->rma_ptr,
+		ret = tcp_sendto(tconn->pfd->fd, tx->buffer, tx->len, tx->rma_ptr,
 				tx->rma_len, &tx->offset);
 		if (ret == CCI_SUCCESS) {
 			if (tx->offset < tx->len)
@@ -2404,7 +2508,7 @@ static int ctp_tcp_rma(cci_connection_t * connection,
 	for (i = 0; i < cnt; i++)
 		TAILQ_INSERT_TAIL(&tconn->queued, &(txs[i])->evt, entry);
 	TAILQ_INSERT_TAIL(&tconn->rmas, rma_op, rmas);
-	tconn->pfd.events = POLLIN | POLLOUT;
+	tconn->pfd->events = POLLIN | POLLOUT;
 	pthread_mutex_unlock(&tconn->lock);
 
 	TAILQ_INSERT_TAIL(&tep->rma_ops, rma_op, entry);
@@ -2449,14 +2553,14 @@ tcp_handle_listen_socket(cci__ep_t *ep, cci__conn_t *listen_conn)
 
 	tconn = conn->priv;
 
-	ret = accept(listen_tconn->pfd.fd, (struct sockaddr *)&sin, &slen);
+	ret = accept(listen_tconn->pfd->fd, (struct sockaddr *)&sin, &slen);
 	if (ret == -1) {
 		ret = errno;
 		debug(CCI_DB_CONN, "%s: accept() failed with %s (%d)",
 			__func__, strerror(ret), ret);
 		goto out;
 	}
-	tconn->pfd.fd = ret;
+	tconn->pfd->fd = ret;
 
 	ret = tcp_monitor_fd(ep, conn, POLLIN);
 	if (ret)
@@ -2530,9 +2634,11 @@ tcp_handle_conn_request(cci__ep_t *ep, cci__conn_t *conn, tcp_rx_t *rx, uint32_t
 	uint32_t rx_cnt, mss, ka, ignore;
 	tcp_ep_t *tep = ep->priv;
 
-	ret = tcp_recv_msg(tconn->pfd.fd, hdr->data, total);
+	ret = tcp_recv_msg(tconn->pfd->fd, hdr->data, total);
 	if (ret) {
 		/* TODO handle error */
+		debug(CCI_DB_CONN, "%s: unable to recv conn %p handshake - %s",
+				__func__, (void*)conn, cci_strerror(&ep->endpoint, ret));
 		goto out;
 	}
 
@@ -2605,9 +2711,11 @@ tcp_handle_conn_reply(cci__ep_t *ep, cci__conn_t *conn, tcp_rx_t *rx,
 		rx->evt.event.connect.connection = NULL;
 
 	if (accepted) {
-		ret = tcp_recv_msg(tconn->pfd.fd, hdr->data, total);
+		ret = tcp_recv_msg(tconn->pfd->fd, hdr->data, total);
 		if (ret) {
 			/* TODO handle error */
+			debug(CCI_DB_CONN, "%s: recv_msg() failed with %d",
+					__func__, ret);
 			tcp_conn_set_closing(ep, conn);
 			rx->evt.event.connect.status = CCI_ERROR;
 			rx->evt.event.connect.connection = NULL;
@@ -2715,7 +2823,7 @@ tcp_handle_send(cci__ep_t *ep, cci__conn_t *conn, tcp_rx_t *rx,
 	debug(CCI_DB_MSG, "%s: recv'd MSG from conn %p with len %u",
 		__func__, (void*)conn, len);
 
-	ret = tcp_recv_msg(tconn->pfd.fd, hdr->data, total);
+	ret = tcp_recv_msg(tconn->pfd->fd, hdr->data, total);
 	if (ret) {
 		/* TODO handle error */
 		goto out;
@@ -2777,7 +2885,7 @@ tcp_handle_rma_write(cci__ep_t *ep, cci__conn_t *conn, tcp_rx_t *rx,
 	debug(CCI_DB_MSG, "%s: recv'ing RMA_WRITE on conn %p with len %u",
 		__func__, (void*)conn, len);
 
-	ret = tcp_recv_msg(tconn->pfd.fd, rma_header->header.data, handle_len);
+	ret = tcp_recv_msg(tconn->pfd->fd, rma_header->header.data, handle_len);
 	if (ret) {
 		/* TODO handle error */
 		goto out;
@@ -2816,7 +2924,7 @@ tcp_handle_rma_write(cci__ep_t *ep, cci__conn_t *conn, tcp_rx_t *rx,
 		/* valid remote handle, copy the data */
 		debug(CCI_DB_INFO, "%s: recv'ing data into target buffer", __func__);
 		ptr = (void*)((uintptr_t)remote->start + (uintptr_t) remote_offset);
-		ret = tcp_recv_msg(tconn->pfd.fd, ptr, len);
+		ret = tcp_recv_msg(tconn->pfd->fd, ptr, len);
 		debug(CCI_DB_MSG, "%s: recv'd data into target buffer", __func__);
 		if (ret)
 			debug(CCI_DB_MSG, "%s: recv'ing RMA WRITE payload failed with %s",
@@ -2832,7 +2940,7 @@ tcp_handle_rma_write(cci__ep_t *ep, cci__conn_t *conn, tcp_rx_t *rx,
 			if (l > (int) (len - offset))
 				l = len - offset;
 
-			tcp_recv_msg(tconn->pfd.fd, tmp, l);
+			tcp_recv_msg(tconn->pfd->fd, tmp, l);
 			offset += l;
 		} while (offset < len);
 	}
@@ -2869,7 +2977,7 @@ tcp_handle_rma_read_request(cci__ep_t *ep, cci__conn_t *conn, tcp_rx_t *rx,
 	debug(CCI_DB_MSG, "%s: recv'ing RMA_READ_REQUEST on conn %p with len %u",
 		__func__, (void*)conn, len);
 
-	ret = tcp_recv_msg(tconn->pfd.fd, read_request->header.data, handle_len);
+	ret = tcp_recv_msg(tconn->pfd->fd, read_request->header.data, handle_len);
 	if (ret) {
 		/* TODO handle error */
 		goto out;
@@ -3016,7 +3124,7 @@ tcp_progress_rma(cci__ep_t *ep, cci__conn_t *conn,
 						1,
 						rma_op->context,
 						rma_op->flags,
-						NULL);
+						rma_op);
 			if (ret) {
 				tx->evt.event.send.status = ret;
 				pthread_mutex_lock(&ep->lock);
@@ -3103,7 +3211,7 @@ tcp_handle_rma_read_reply(cci__ep_t *ep, cci__conn_t *conn, tcp_rx_t *rx,
 	debug(CCI_DB_MSG, "%s: recv'ing RMA_READ_REPLY on conn %p with len %u",
 		__func__, (void*)conn, len);
 
-	ret = tcp_recv_msg(tconn->pfd.fd, rma_header->header.data, handle_len);
+	ret = tcp_recv_msg(tconn->pfd->fd, rma_header->header.data, handle_len);
 	if (ret) {
 		/* TODO handle error */
 		debug(CCI_DB_MSG, "%s: recv_msg() returned %s",
@@ -3143,7 +3251,7 @@ tcp_handle_rma_read_reply(cci__ep_t *ep, cci__conn_t *conn, tcp_rx_t *rx,
 	/* valid local handle, copy the data */
 	debug(CCI_DB_INFO, "%s: recv'ing data into target buffer", __func__);
 	ptr = (void*)((uintptr_t)local->start + (uintptr_t) local_offset);
-	ret = tcp_recv_msg(tconn->pfd.fd, ptr, len);
+	ret = tcp_recv_msg(tconn->pfd->fd, ptr, len);
 	debug(CCI_DB_MSG, "%s: recv'd data into target buffer", __func__);
 	if (ret)
 		debug(CCI_DB_MSG, "%s: recv'ing RMA READ payload failed with %s",
@@ -3240,7 +3348,7 @@ tcp_handle_recv(cci__ep_t *ep, cci__conn_t *conn)
 	rx->evt.conn = conn;
 	hdr = rx->buffer;
 
-	ret = tcp_recv_msg(tconn->pfd.fd, hdr, len);
+	ret = tcp_recv_msg(tconn->pfd->fd, hdr, len);
 	if (ret) {
 		/* TODO handle error */
 		debug(CCI_DB_MSG, "%s: tcp_recv_msg() returned %d (rx=%p hdr=%p)",
@@ -3367,10 +3475,6 @@ delete_conn_locked(cci__conn_t *conn)
 
 	free((char *)conn->uri);
 
-#if CCI_DEBUG
-	memset(tconn, 0xFF, sizeof(*tconn));
-	memset(conn, 0xFF, sizeof(*conn));
-#endif
 	free(tconn);
 	free(conn);
 	return;
@@ -3496,11 +3600,11 @@ tcp_poll_events(cci__ep_t *ep)
 	/* Note: we have a ref on this conn */
 
 	if (!tconn->is_listener && tconn->status > TCP_CONN_INIT)
-		tconn->pfd.events = POLLIN | POLLOUT;
+		tconn->pfd->events = POLLIN | POLLOUT;
 
 	/* Another thread may have called disconnect() since we got it above and
 	 * closed the conn's fd. If so, we will get POLLNVAL. */
-	ret = poll(&tconn->pfd, 1, 0);
+	ret = poll(tconn->pfd, 1, 0);
 	if (ret < 1) {
 		if (ret == -1) {
 			ret = errno;
@@ -3512,7 +3616,7 @@ tcp_poll_events(cci__ep_t *ep)
 		goto out;
 	}
 
-	revents = tconn->pfd.revents;
+	revents = tconn->pfd->revents;
 
 	events(revents, str, POLL_EVENTS_LEN);
 	debug(CCI_DB_EP, "%s: poll() on conn %p found events %s", __func__,
@@ -3591,11 +3695,11 @@ tcp_poll_events(cci__ep_t *ep)
 
 		if (tconn->status == TCP_CONN_ACTIVE1) {
     again:
-			rc = getsockopt(tconn->pfd.fd, SOL_SOCKET, SO_ERROR, (void*)pe, &slen);
+			rc = getsockopt(tconn->pfd->fd, SOL_SOCKET, SO_ERROR, (void*)pe, &slen);
 			if (rc) {
 				debug(CCI_DB_CONN, "%s: getsockopt() for conn %p (fd %d) "
 					"failed with %s", __func__, (void*)conn,
-					tconn->pfd.fd, strerror(errno));
+					tconn->pfd->fd, strerror(errno));
 				if (errno == EBADF) {
 					/* TODO close connection */
 					assert(0);
@@ -3611,7 +3715,7 @@ tcp_poll_events(cci__ep_t *ep)
 					__func__, (void*)conn);
 				pthread_mutex_lock(&ep->lock);
 				tconn->status = TCP_CONN_ACTIVE2;
-				tconn->pfd.events = POLLIN | POLLOUT;
+				tconn->pfd->events = POLLIN | POLLOUT;
 				pthread_mutex_unlock(&ep->lock);
 			} else {
 				/* TODO close connection */
@@ -3636,11 +3740,21 @@ out:
 static void *tcp_progress_thread(void *arg)
 {
 	cci__ep_t *ep = (cci__ep_t *) arg;
+	tcp_ep_t *tep = NULL;
 
 	assert (ep);
 
-	while (!ep->closing)
+	tep = ep->priv;
+
+	while (!ep->closing) {
+		int ret = 0;
+
+		ret = poll(tep->fds, tep->nfds, 1000);
+		if (ret < 1)
+			continue;
+
 		tcp_progress_ep(ep);
+	}
 
 	pthread_exit(NULL);
 	return (NULL);		/* make pgcc happy */
diff --git a/src/plugins/ctp/verbs/ctp_verbs.h b/src/plugins/ctp/verbs/ctp_verbs.h
index c4fa95b..3e4bf67 100644
--- a/src/plugins/ctp/verbs/ctp_verbs.h
+++ b/src/plugins/ctp/verbs/ctp_verbs.h
@@ -392,7 +392,9 @@ typedef struct verbs_conn {
 	uint32_t last;		/* last slot used */
 	uint32_t **slots;	/* pointers to buffer headers
 				   to poll */
-	int is_polling;		/* polling RDMA MSGs */
+	uint32_t is_polling :1;	/* polling RDMA MSGs */
+	uint32_t rdma_disconn :1; /* still needs rdma_disconnect */
+	uint32_t cci_disconn :1; /* still needs cci_disconnect */
 
 	/* for RO connections when using both SendRecv and RDMA */
 	uint16_t seqno;		/* last seqno sent */
diff --git a/src/plugins/ctp/verbs/ctp_verbs_api.c b/src/plugins/ctp/verbs/ctp_verbs_api.c
index 5a29ac3..06da1f4 100644
--- a/src/plugins/ctp/verbs/ctp_verbs_api.c
+++ b/src/plugins/ctp/verbs/ctp_verbs_api.c
@@ -1724,8 +1724,8 @@ verbs_post_send(cci__conn_t * conn, uint64_t id, void *buffer, uint32_t len,
 	}
 
 	ret = ibv_post_send(vconn->id->qp, &wr, &bad_wr);
-	if (ret == -1) {
-		ret = errno;
+	if (ret) {
+		ret = verbs_wc_to_cci_status(ret);
 		debug(CCI_DB_MSG,
 		      "unable to send id 0x%" PRIx64
 		      " buffer %p len %u header 0x%x", id, (void*)buffer, len, header);
@@ -2034,6 +2034,7 @@ verbs_insert_conn(cci__conn_t *conn)
 	pthread_rwlock_unlock(&vep->conn_tree_lock);
 	pthread_mutex_lock(&ep->lock);
 	TAILQ_INSERT_TAIL(&vep->conns, vconn, entry);
+	vconn->cci_disconn = 1;
 	pthread_mutex_unlock(&ep->lock);
 	debug(CCI_DB_CONN, "%s [%s]: added conn %p qp_num %u", __func__,
 		ep->uri, (void*)conn, vconn->qp_num);
@@ -2345,20 +2346,23 @@ out:
 
 static const char *verbs_conn_state_str(verbs_conn_state_t state);
 
-static int ctp_verbs_disconnect(cci_connection_t * connection)
+static void verbs_destroy_conn(cci__ep_t *ep, cci__conn_t *conn)
 {
-	int ret = CCI_SUCCESS;
-	cci__conn_t *conn = container_of(connection, cci__conn_t, connection);
-	verbs_conn_t *vconn = conn->priv;
-	cci_endpoint_t *endpoint = connection->endpoint;
-	cci__ep_t *ep = container_of(endpoint, cci__ep_t, endpoint);
+	int ret = 0;
 	verbs_ep_t *vep = ep->priv;
+	verbs_conn_t *vconn = conn->priv;
 
-	CCI_ENTER;
+	debug(CCI_DB_CONN, "%s: conn %p vconn %p qp_num %u (%s)",
+		__func__, (void*) conn, (void*)vconn, vconn->qp_num, conn->uri);
 
-	debug(CCI_DB_CONN, "%s [%s]: conn %p state %s qp_num %u", __func__,
-		ep->uri, (void*)conn, verbs_conn_state_str(vconn->state),
-		vconn->qp_num);
+	if (vconn->rdma_disconn) {
+		ret = rdma_disconnect(vconn->id);
+		if (ret == -1) {
+			ret = errno;
+			debug(CCI_DB_WARN, "%s: rdma_disconnect() returned %s",
+			      __func__, strerror(ret));
+		}
+	}
 
 	pthread_rwlock_wrlock(&vep->conn_tree_lock);
 	tdelete(&vconn->qp_num, &vep->conn_tree, verbs_compare_u32);
@@ -2377,13 +2381,6 @@ static int ctp_verbs_disconnect(cci_connection_t * connection)
 			free(vconn->conn_req->ptr);
 	}
 
-	ret = rdma_disconnect(vconn->id);
-	if (ret == -1) {
-		ret = errno;
-		debug(CCI_DB_WARN, "%s: rdma_disconnect() returned %s",
-		      __func__, strerror(ret));
-	}
-
 	if (vconn->rbuf) {
 		if (vconn->rmr) {
 			ret = ibv_dereg_mr(vconn->rmr);
@@ -2399,12 +2396,49 @@ static int ctp_verbs_disconnect(cci_connection_t * connection)
 		free(vconn->rbuf);
 	}
 
-	rdma_destroy_ep(vconn->id);
-
 	free((void *)conn->uri);
 	free(vconn);
 	free(conn);
 
+	return;
+}
+
+static int ctp_verbs_disconnect(cci_connection_t * connection)
+{
+	int ret = CCI_SUCCESS;
+	cci__conn_t *conn = container_of(connection, cci__conn_t, connection);
+	verbs_conn_t *vconn = conn->priv;
+	cci_endpoint_t *endpoint = connection->endpoint;
+	cci__ep_t *ep = container_of(endpoint, cci__ep_t, endpoint);
+	verbs_ep_t *vep = ep->priv;
+	int rdma_disconn = 0;
+
+	CCI_ENTER;
+
+	debug(CCI_DB_CONN, "%s [%s]: conn %p state %s qp_num %u", __func__,
+		ep->uri, (void*)conn, verbs_conn_state_str(vconn->state),
+		vconn->qp_num);
+
+	vconn->cci_disconn = 0;
+
+	if (vconn->rdma_disconn) {
+		/* The conn is established and we are the one trying to
+		 * tear it down.
+		 */
+		ret = rdma_disconnect(vconn->id);
+		if (ret == -1) {
+			ret = errno;
+			debug(CCI_DB_WARN, "%s: rdma_disconnect() returned %s",
+			      __func__, strerror(ret));
+		}
+		vconn->rdma_disconn = 0;
+	} else {
+		/* We have already received the RDMA_CM_EVENT_DISCONNECTED
+		 * event. Go ahead and cleanup.
+		 */
+		verbs_destroy_conn(ep, conn);
+	}
+
 	CCI_EXIT;
 	return ret;
 }
@@ -2891,6 +2925,13 @@ verbs_handle_conn_established(cci__ep_t * ep, struct rdma_cm_event *cm_evt)
 	vconn = conn->priv;
 	assert(vconn);
 
+	/* The RDMA connection is established. We will need to call
+	 * rdma_disconnect() in the future.
+	 */
+	pthread_mutex_lock(&ep->lock);
+	vconn->rdma_disconn = 1;
+	pthread_mutex_unlock(&ep->lock);
+
 	switch (vconn->state) {
 	case VERBS_CONN_ACTIVE:
 		ret = verbs_conn_est_active(ep, cm_evt);
@@ -2924,22 +2965,61 @@ verbs_handle_disconnected(cci__ep_t * ep, struct rdma_cm_event *cm_evt)
 	vconn = conn->priv;
 	assert(vconn);
 
-	switch (vconn->state) {
-	case VERBS_CONN_ESTABLISHED:
-		vconn->state = VERBS_CONN_CLOSED;
-		debug(CCI_DB_CONN, "%s: marking vconn %p closed (%s)",
-			__func__, (void*)vconn, conn->uri);
-		break;
-	default:
-		debug(CCI_DB_INFO, "%s: incorrect conn state %s", __func__,
-		      verbs_conn_state_str(vconn->state));
-		break;
+	if (vconn->rdma_disconn) {
+		/* We did not initiate the disconnect. We will not get
+		 * another RDMA_CM_EVENT_DISCONNECTED, so go ahead and
+		 * call it now.
+		 */
+		ret = rdma_disconnect(vconn->id);
+		if (ret == -1) {
+			ret = errno;
+			debug(CCI_DB_WARN, "%s: rdma_disconnect() returned %s",
+			      __func__, strerror(ret));
+		}
+		vconn->rdma_disconn = 0;
+	}
+
+	/* Either way, we got the DISCONNECTED event, it is safe to cleanup
+	 * the QP and CM id.
+	 */
+	ret = rdma_destroy_ep(vconn->id);
+	if (ret == -1) {
+		ret = errno;
+		debug(CCI_DB_WARN, "%s: rdma_destroy_ep() returned %s",
+		      __func__, strerror(ret));
+	}
+
+	if (!vconn->cci_disconn) {
+		verbs_destroy_conn(ep, conn);
 	}
 
 	CCI_EXIT;
 	return ret;
 }
 
+static void
+verbs_handle_timewait_exit(cci__ep_t * ep, struct rdma_cm_event *cm_evt)
+{
+	/* The CM can reuse the QP now. We should have already torn down the
+	 * QP, destroyed the RDMA id, and freed the CCI conn. Simply
+	 * print the QP number and the possibly freed CCI conn address
+	 * for informational purposes.
+	 */
+	debug(CCI_DB_CONN, "%s: qp_num %u context (conn) %p", __func__,
+		cm_evt->id->qp->qp_num, cm_evt->id->context);
+
+	return;
+}
+
+static void
+verbs_handle_connect_error(cci__ep_t * ep, struct rdma_cm_event *cm_evt)
+{
+	debug(CCI_DB_WARN, "%s: qp_num %u context (conn) %p", __func__,
+		cm_evt->id->qp->qp_num, cm_evt->id->context);
+
+	return;
+}
+
 static int verbs_get_cm_event(cci__ep_t * ep)
 {
 	int ret = CCI_EAGAIN;
@@ -2986,6 +3066,12 @@ static int verbs_get_cm_event(cci__ep_t * ep)
 			debug(CCI_DB_CONN, "%s: verbs_handle_conn_rejected()"
 			      "returned %s", __func__, strerror(ret));
 		break;
+	case RDMA_CM_EVENT_TIMEWAIT_EXIT:
+		verbs_handle_timewait_exit(ep, cm_evt);
+		break;
+	case RDMA_CM_EVENT_CONNECT_ERROR:
+		verbs_handle_connect_error(ep, cm_evt);
+		break;
 	default:
 		debug(CCI_DB_CONN, "ignoring %s event",
 		      rdma_event_str(cm_evt->event));
@@ -4337,7 +4423,7 @@ static int verbs_post_rma(verbs_rma_op_t * rma_op)
 
 	ret = ibv_post_send(vconn->id->qp, &wr, &bad_wr);
 	if (ret) {
-		ret = verbs_wc_to_cci_status(errno);
+		ret = verbs_wc_to_cci_status(ret);
 		debug(CCI_DB_MSG, "%s: ibv_post_send() failed with %s (cci %s)",
 				__func__, ibv_wc_status_str(errno),
 				cci_strerror(&(rma_op->evt.ep)->endpoint, ret));
diff --git a/src/tests/connect_test.c b/src/tests/connect_test.c
new file mode 100644
index 0000000..47ac556
--- /dev/null
+++ b/src/tests/connect_test.c
@@ -0,0 +1,780 @@
+/*
+ * Copyright (c) 2016 UT-Battelle, LLC.  All rights reserved.
+ *
+ * See COPYING in top-level directory
+ *
+ * $COPYRIGHT$
+ *
+ */
+
+#include <stdio.h>
+#include <string.h>
+#include <strings.h>
+#include <stdlib.h>
+#include <unistd.h>
+#include <inttypes.h>
+#include <assert.h>
+#include <sys/time.h>
+#include <sys/select.h>
+#include <bsd/queue.h>
+#include <pthread.h>
+
+#include "cci.h"
+
+#define NUM_EPS		(1)
+#define NUM_EP_THREADS	(1)
+#define NUM_EP_CONNS	(8)
+#define CONN_MAX	(10000)
+
+char *name;			/* argv[0] */
+
+cci_device_t **devices = NULL;
+int blocking = 0;
+int nfds = 0;
+fd_set rfds;
+int attempts = 0;
+
+/* The client sends the CCI RMA handle for its test->control->buffer */
+typedef enum msg_type {
+	SERVER_INFO	= 0,	/* client <- server */
+	SEND,
+	RMA_DONE,
+	SHUTDOWN
+} msg_type_t;
+
+/* Must be four-byte aligned */
+typedef struct server_info {
+	cci_rma_handle_t handle;	/* server's RMA handle */
+	uint32_t len;			/* length of endpoint URI */
+	char uri[1];			/* start of URI */
+} info_t;
+
+typedef union msg {
+	struct msg_generic {
+		uint32_t type	:  4;	/* msg_type */
+		uint32_t pad	: 28;
+	} generic;
+
+	struct msg_server_info {
+		uint32_t type	:  4;	/* SERVER_INFO */
+		uint32_t count	:  8;	/* number of server infos */
+		uint32_t pad	: 20;
+	} info;
+
+	struct msg_shutdown {
+		uint32_t type	:  4;	/* SHUTDOWN */
+		uint32_t pad	: 28;
+	} shutdown;
+} msg_t;
+
+typedef struct conn conn_t;
+typedef struct thread thread_t;
+typedef struct ep ep_t;
+typedef struct server server_t;
+typedef struct test test_t;
+
+struct conn {
+	cci_connection_t *c;
+	char *server_uri;
+	TAILQ_ENTRY(conn) entry;	/* hang on ep->conns */
+	cci_conn_attribute_t attr;
+	int pattern;
+	int number;
+};
+
+struct thread {
+	ep_t *ep;			/* owning endpoint */
+	TAILQ_ENTRY(thread) entry;	/* hang on ep->threads */
+	pthread_t tid;
+	int id;
+	int conns_open;
+	int conns_closed;
+};
+
+struct ep {
+	test_t *test;
+	cci_endpoint_t *e;
+	TAILQ_HEAD(t, thread) threads;	/* running threads */
+	TAILQ_HEAD(c, conn) conns;	/* test connections */
+	TAILQ_ENTRY(ep) entry;		/* hang on test->eps */
+	pthread_mutex_t lock;		/* threads, conns, conns_open, conns_closed */
+	void *buffer;			/* RMA buffer */
+	cci_rma_handle_t *handle;
+	char *uri;
+	int id;
+	int conns_open;		/* aggregate of all threads */
+	int conns_closed;	/* aggregate of all threads */
+	int fd;
+};
+
+struct server {
+	cci_rma_handle_t *handle;
+	char *uri;		/* server's CCI endpoint URI */
+};
+
+struct test {
+	TAILQ_HEAD(e, ep) eps;		/* open CCI endpoints */
+	server_t *servers;		/* array of server endpoints */
+	pthread_mutex_t lock;		/* eps, next_conn */
+	ep_t *control;			/* control endpoint - not used for tests */
+	int num_eps;			/* open this many endpoints */
+	int num_ep_threads;		/* use this many threads per endpoint */
+	int num_ep_conns;		/* open conns per endpoint */
+	int next_conn;			/* incremental conn IDs */
+	int num_servers;		/* number of servers in array */
+	int conn_max;		/* End test after this many connections... */
+	int secs;		/*     or this many seconds                */
+	int blocking;
+#define ROLE_SERVER	(1)
+#define ROLE_CLIENT	(2)
+	int role;
+	int ready;
+	int done;
+};
+
+
+static void print_usage(void)
+{
+	fprintf(stderr, "usage: %s "
+			"[-e <num_endpoints>] "
+			"[-t <threads_per_enpoint>] "
+			"[-c <open_conns_per_endpoint>] "
+			"[-h <server_uri> | -s] "
+			"[-S <service>] "
+			"[-n <num_conns> | -T <secs>] "
+			"[-b]\n", name);
+	fprintf(stderr, "where:\n");
+	fprintf(stderr, "\t-e\tOpen this number of CCI endpoints (default %d)\n", NUM_EPS);
+	fprintf(stderr, "\t-t\tThreads per CCI endpoint (default %d)\n", NUM_EP_THREADS);
+	fprintf(stderr, "\t-c\tNumber of open connections per endpoint "
+			"(client only) (default %d)\n", NUM_EP_CONNS);
+	fprintf(stderr, "\t-h\tRun as client and connect to server at this URI\n");
+	fprintf(stderr, "\t-s\tRun as the server\n");
+	fprintf(stderr, "\t-S\tSpecify a service hint for the control endpoint()\n\n");
+	fprintf(stderr, "\t-n\tTest this number of connections (default %d)\n", CONN_MAX);
+	fprintf(stderr, "\t-T\tRun for this number of seconds\n");
+	fprintf(stderr, "\t-b\tBlock using the OS handle instead of polling\n");
+	fprintf(stderr, "Example:\n");
+	fprintf(stderr, "server$ %s -s -S 5000 -e 2 -t 8\n", name);
+	fprintf(stderr, "client$ %s -h tcp://host:5000 -e 1 -t 4 -c 20\n", name);
+	exit(EXIT_FAILURE);
+}
+
+static void check_return(test_t *test, char *func, int ret, int need_exit)
+{
+	conn_t *conn = TAILQ_FIRST(&test->control->conns);
+
+	if (ret) {
+		fprintf(stderr, "%s() returned %s\n", func,
+				cci_strerror(test->control->e, ret));
+		if (need_exit) {
+			cci_send(conn->c, "bye", 3, (void *)0xdeadbeef, CCI_FLAG_BLOCKING);
+			cci_finalize();
+			exit(EXIT_FAILURE);
+		}
+	}
+	return;
+}
+
+static void
+do_client(test_t *test)
+{
+	int ret = 0, try = 0, i = 0, done = 0;
+	conn_t *conn = TAILQ_FIRST(&test->control->conns);
+	cci_event_t *event = NULL;
+	msg_t *msg = NULL;
+	uintptr_t offset = 0;
+
+	/* connect to server */
+	do {
+		ret = cci_connect(test->control->e, conn->server_uri,
+				(void*)test->control->handle,
+				sizeof(*test->control->handle),
+				CCI_CONN_ATTR_RO, NULL, 0, NULL);
+		if (ret) {
+			fprintf(stderr, "cci_connect() failed with %s\n",
+					cci_strerror(test->control->e, ret));
+			continue;
+		}
+
+		do {
+			ret = cci_get_event(test->control->e, &event);
+		} while (ret);
+
+		assert(event->type == CCI_EVENT_CONNECT);
+
+		conn->c = event->connect.connection;
+
+		if (event->connect.status)
+			fprintf(stderr, "CONNECT event status is %d\n",
+					event->connect.status);
+
+		cci_return_event(event);
+
+		if (!conn->c)
+			sleep(1);
+
+	} while (!conn->c && try++ < 60);
+
+	if (!conn->c)
+		return;
+
+	/* wait for server's endpoint info */
+	do {
+		cci_get_event(test->control->e, &event);
+	} while (!event);
+
+	assert(event->type == CCI_EVENT_RECV);
+
+	msg = (void*) event->recv.ptr;
+	assert(msg->info.type == SERVER_INFO);
+
+	/* store server info */
+	test->num_servers = msg->info.count;
+
+	test->servers = calloc(test->num_servers, sizeof(*test->servers));
+	if (!test->servers) {
+		fprintf(stderr, "%s: calloc(test->servers) failed\n", __func__);
+		goto out;
+	}
+
+	offset = (uintptr_t)test->control->buffer;
+
+	for (i = 0; i < test->num_servers; i++) {
+		info_t *info = NULL;
+		server_t *server = NULL;
+
+		server = &test->servers[i];
+		server->handle = calloc(1, sizeof(*server->handle));
+		if (!server->handle) {
+			fprintf(stderr, "%s: calloc(server->handle[%d]) failed\n",
+					__func__, i);
+			break;
+		}
+
+		info = (void*)offset;
+
+		memcpy(&server->handle, &info->handle, sizeof(*server->handle));
+
+		server->uri = calloc(1, info->len + 1);
+		if (!server->uri) {
+			fprintf(stderr, "%s: calloc(server->uri[%d]) failed\n",
+					__func__, i);
+			break;
+		}
+		memcpy(server->uri, info->uri, info->len);
+
+		offset = (uintptr_t)&info->uri; /* move to the start of the URI */
+		offset += info->len; /* move to the end of the URI */
+		if (offset % 8) {
+			/* if not 8-byte aligned, align it */
+			offset += (8 - (offset % 8));
+			assert((offset % 8) == 0);
+		}
+	}
+
+	cci_return_event(event);
+
+	/* we are ready to go */
+
+	pthread_mutex_lock(&test->lock);
+	test->ready = 1;
+	pthread_mutex_unlock(&test->lock);
+
+	do {
+		int shutdown = 0;
+
+		sleep(1);
+
+		ret = cci_get_event(test->control->e, &event);
+		if (!ret) {
+			msg_t *msg = NULL;
+
+			assert(event->type == CCI_EVENT_RECV);
+
+			msg = (void*)event->recv.ptr;
+			assert(msg->shutdown.type == SHUTDOWN);
+
+			cci_return_event(event);
+
+			shutdown = 1;
+			done++;
+		}
+
+		pthread_mutex_lock(&test->lock);
+		if (test->done)
+			done++;
+
+		if (shutdown)
+			test->done = 1;
+		pthread_mutex_unlock(&test->lock);
+
+		if (!shutdown) {
+			msg_t shutdown;
+
+			shutdown.shutdown.type = SHUTDOWN;
+
+			ret = cci_send(conn->c, &shutdown, sizeof(shutdown),
+					(void*)0x987654321, 0);
+			check_return(test, "cci_send(shutdown)", ret, 1);
+
+			while (1) {
+				ret = cci_get_event(test->control->e, &event);
+				if (ret) continue;
+
+				if (event->type == CCI_EVENT_SEND) {
+					if (event->send.context == (void*)0x987654321)
+						break;
+				}
+
+				cci_return_event(event);
+			}
+		}
+	} while (!done);
+
+    out:
+	cci_disconnect(conn->c);
+
+	return;
+}
+
+static void *
+server_thread(void *arg)
+{
+	pthread_exit(NULL);
+}
+
+static void
+do_server(test_t *test)
+{
+	int ret = 0, len = 0, done = 0;
+	ep_t *ep = NULL;
+	conn_t *conn = TAILQ_FIRST(&test->control->conns);
+	cci_event_t *event = NULL;
+	msg_t msg;
+	uintptr_t offset = 0;
+	info_t *info = NULL;
+	cci_rma_handle_t client_handle;
+
+	/* wait for client to connect */
+	do {
+		ret = cci_get_event(test->control->e, &event);
+	} while (ret);
+
+	assert(event->type == CCI_EVENT_CONNECT_REQUEST);
+
+	memcpy((void*)&client_handle, event->request.data_ptr, event->request.data_len);
+
+	ret = cci_accept(event, NULL);
+	if (ret) {
+		fprintf(stderr, "%s: cci_accept() failed with %s\n",
+				__func__, cci_strerror(test->control->e, ret));
+		goto out;
+	}
+
+	ret = cci_return_event(event);
+	if (ret) {
+		fprintf(stderr, "%s: cci_return_event() failed with %s\n",
+				__func__, cci_strerror(test->control->e, ret));
+		goto out;
+	}
+
+	/* wait for the accept event */
+	do {
+		cci_get_event(test->control->e, &event);
+	} while (!event);
+
+	assert(event->type == CCI_EVENT_ACCEPT);
+
+	conn->c = event->accept.connection;
+
+	if (event->accept.status)
+		fprintf(stderr, "%s: ACCEPT failed with %s\n",
+				__func__, cci_strerror(test->control->e,
+					event->accept.status));
+
+	assert(conn->c);
+
+	/* send endpoint info */
+
+	TAILQ_FOREACH(ep, &test->eps, entry) {
+		len += sizeof(*info) + strlen(ep->uri) + 1;
+		if (len % 8)
+			len += (8 - (len % 8));
+	}
+
+	msg.info.type = SERVER_INFO;
+	msg.info.count = test->num_eps;
+
+	offset = (uintptr_t)test->control->buffer;
+
+	TAILQ_FOREACH(ep, &test->eps, entry) {
+		info = (void*)offset;
+
+		memcpy((void*)&info->handle, ep->handle, sizeof(info->handle));
+		info->len = strlen(ep->uri);
+		memcpy(info->uri, ep->uri, info->len);
+
+		/* ensure the offset is 8-byte aligned */
+		offset = (uintptr_t)&info->uri; /* move to the start of the URI */
+		offset += info->len; /* move to the end of the URI */
+		if (offset % 8) {
+			/* if not 8-byte aligned, align it */
+			offset += (8 - (offset % 8));
+			assert((offset % 8) == 0);
+		}
+	}
+
+	ret = cci_rma(conn->c, &msg, sizeof(msg),
+			test->control->handle, 0,
+			&client_handle, 0,
+			(uint64_t)(offset - (uintptr_t)test->control->buffer),
+			NULL, CCI_FLAG_WRITE);
+	check_return(test, "cci_rma", ret, 1);
+
+	do {
+		cci_get_event(test->control->e, &event);
+	} while (!event);
+
+	assert(event->type == CCI_EVENT_SEND);
+
+	ret = cci_return_event(event);
+	check_return(test, "cci_return_event(rma)", ret, 1);
+
+	do {
+		int shutdown = 0;
+
+		sleep(1);
+
+		ret = cci_get_event(test->control->e, &event);
+		if (!ret) {
+			msg_t *msg = NULL;
+
+			assert(event->type == CCI_EVENT_RECV);
+
+			msg = (void*)event->recv.ptr;
+			assert(msg->shutdown.type == SHUTDOWN);
+
+			cci_return_event(event);
+
+			shutdown = 1;
+			done++;
+		}
+
+		pthread_mutex_lock(&test->lock);
+		if (test->done)
+			done++;
+
+		if (shutdown)
+			test->done = 1;
+		pthread_mutex_unlock(&test->lock);
+
+		if (!shutdown) {
+			msg_t shutdown;
+
+			shutdown.shutdown.type = SHUTDOWN;
+
+			ret = cci_send(conn->c, &shutdown, sizeof(shutdown),
+					(void*)0x987654321, 0);
+			check_return(test, "cci_send(shutdown)", ret, 1);
+
+			while (1) {
+				ret = cci_get_event(test->control->e, &event);
+				if (ret) continue;
+
+				if (event->type == CCI_EVENT_SEND) {
+					if (event->send.context == (void*)0x987654321)
+						break;
+				}
+
+				cci_return_event(event);
+			}
+		}
+	} while (!done);
+
+    out:
+	pthread_mutex_lock(&test->lock);
+	test->done = 1;
+	pthread_mutex_unlock(&test->lock);
+
+	return;
+}
+
+static void *
+client_thread(void *arg)
+{
+	pthread_exit(NULL);
+}
+
+static int
+create_threads(test_t *test, ep_t *ep)
+{
+	int ret = 0, i = 0;
+	void *(*func)(void*) = test->role == ROLE_SERVER ? server_thread : client_thread;
+
+	for (i = 0; i < test->num_ep_threads; i++) {
+		thread_t *thread = NULL;
+
+		thread = calloc(1, sizeof(*thread));
+		if (!thread) {
+			ret = ENOMEM;
+			goto out;
+		}
+
+		thread->ep = ep;
+		thread->id = i;
+		TAILQ_INSERT_TAIL(&ep->threads, thread, entry);
+		ret = pthread_create(&thread->tid, NULL, func, (void*)thread);
+		if (ret) {
+			fprintf(stderr, "%s: pthread_create(%d) failed with %s\n",
+					__func__, i, strerror(ret));
+			goto out;
+		}
+	}
+
+    out:
+	return ret;
+}
+
+static int
+create_endpoints(test_t *test)
+{
+	int ret = 0, i = 0;
+
+	for (i = 0; i < test->num_eps; i++) {
+		ep_t *ep = NULL;
+		cci_os_handle_t *fd = NULL;
+
+		if (test->blocking)
+			fd = &ep->fd;
+
+		ep = calloc(1, sizeof(*ep));
+		if (!ep) {
+			fprintf(stderr, "%s: calloc(ep%d) failed\n", __func__, i);
+			ret = ENOMEM;
+			goto out;
+		}
+
+		ep->test = test;
+
+		ret = cci_create_endpoint(NULL, 0, &ep->e, fd);
+		if (ret) {
+			fprintf(stderr, "%s: cci_create_endpoint(%d) failed with %s (%d)\n",
+				__func__, i, cci_strerror(NULL, ret), ret);
+			goto out;
+		}
+
+		TAILQ_INIT(&ep->threads);
+		TAILQ_INIT(&ep->conns);
+		ret = pthread_mutex_init(&ep->lock, NULL);
+		if (ret) {
+			fprintf(stderr, "%s: calloc(ep%d) failed with %s\n",
+					__func__, i, strerror(ret));
+			goto out;
+		}
+
+		ep->buffer = malloc(1024*1024);
+		if (!ep->buffer) {
+			fprintf(stderr, "%s: malloc(ep%d) failed\n", __func__, i);
+			ret = ENOMEM;
+			goto out;
+		}
+
+		ret = cci_rma_register(ep->e, ep->buffer, 1024*1024,
+				CCI_FLAG_READ|CCI_FLAG_WRITE, &ep->handle);
+		if (ret) {
+			fprintf(stderr, "%s: cci_rma_register(%d) failed with %s (%d)\n",
+				__func__, i, cci_strerror(ep->e, ret), ret);
+			goto out;
+		}
+		ret = cci_get_opt(ep->e, CCI_OPT_ENDPT_URI, &ep->uri);
+		if (ret) {
+			fprintf(stderr, "%s: cci_get_opt(%d) failed with %s\n",
+					__func__, i, cci_strerror(ep->e, ret));
+			goto out;
+		}
+		ep->id = i;
+
+		TAILQ_INSERT_TAIL(&test->eps, ep, entry);
+
+		ret = create_threads(test, ep);
+		if (ret) goto out;
+	}
+
+    out:
+	return ret;
+}
+
+int main(int argc, char *argv[])
+{
+	int ret, c, is_server = 0;
+	uint32_t caps = 0;
+	char *service = NULL;
+	cci_os_handle_t *os_handle = NULL;
+	test_t *test = NULL;
+	conn_t *conn = NULL;
+
+	name = argv[0];
+
+	test = calloc(1, sizeof(*test));
+	if (!test) {
+		fprintf(stderr, "calloc(test) failed\n");
+		exit(EXIT_FAILURE);
+	}
+	TAILQ_INIT(&test->eps);
+	ret = pthread_mutex_init(&test->lock, NULL);
+	if (ret) {
+		fprintf(stderr, "pthread_mutex_init(test->lock) failed with %s\n",
+				strerror(ret));
+		goto out_w_test;
+	}
+	test->num_eps = NUM_EPS;
+	test->num_ep_threads = NUM_EP_THREADS;
+	test->num_ep_conns = NUM_EP_CONNS;
+	test->conn_max = CONN_MAX;
+	test->secs = 0;
+
+	test->control = calloc(1, sizeof(*test->control));
+	if (!test->control) {
+		fprintf(stderr, "calloc(test->control) failed\n");
+		goto out_w_test;
+	}
+	test->control->test = test;
+	TAILQ_INIT(&test->control->threads);
+	TAILQ_INIT(&test->control->conns);
+	ret = pthread_mutex_init(&test->control->lock, NULL);
+	if (ret) {
+		fprintf(stderr, "pthread_mutex_init(test->control->lock) failed with %s\n",
+				strerror(ret));
+		goto out_w_control;
+	}
+	test->control->buffer = calloc(1, 1024*1024);
+	if (!test->control->buffer) {
+		fprintf(stderr, "calloc(control->buffer) failed\n");
+		goto out_w_control;
+	}
+
+	conn = calloc(1, sizeof(*conn));
+	if (!conn) {
+		fprintf(stderr, "calloc(conn) failed\n");
+		goto out_w_buffer;
+	}
+	TAILQ_INSERT_TAIL(&test->control->conns, conn, entry);
+
+	while ((c = getopt(argc, argv, "e:t:c:h:sS:n:T:b")) != -1) {
+		switch (c) {
+		case 'e':
+			test->num_eps = strtol(optarg, NULL, 0);
+			/* the msg->info.count uses 8 bits */
+			assert(test->num_eps < 256);
+			break;
+		case 't':
+			test->num_ep_threads = strtol(optarg, NULL, 0);
+			break;
+		case 'c':
+			test->num_ep_conns = strtol(optarg, NULL, 0);
+			break;
+		case 'h':
+			test->role = ROLE_CLIENT;
+			conn->server_uri = strdup(optarg);
+			break;
+		case 's':
+			test->role = ROLE_SERVER;
+			is_server = 1;
+			break;
+		case 'S':
+			service = strdup(optarg);
+			if (!service)
+				fprintf(stderr, "strdup(service) failed.\n");
+			break;
+		case 'n':
+			test->conn_max = strtoul(optarg, NULL, 0);
+			break;
+		case 'T':
+			test->secs = strtoul(optarg, NULL, 0);
+			break;
+		case 'b':
+			test->blocking = 1;
+			os_handle = &test->control->fd;
+			break;
+		default:
+			print_usage();
+		}
+	}
+
+	if (!is_server && !conn->server_uri) {
+		fprintf(stderr, "Must select -h or -s\n");
+		print_usage();
+	}
+
+	ret = cci_init(CCI_ABI_VERSION, 0, &caps);
+	if (ret) {
+		fprintf(stderr, "cci_init() failed with %s\n",
+			cci_strerror(NULL, ret));
+		goto out_w_conn;
+	}
+
+	/* create an endpoint */
+	if (service) {
+		cci_device_t * const * devices = NULL;
+		ret = cci_get_devices(&devices);
+		if (ret != CCI_SUCCESS) {
+			fprintf(stderr, "%s: cci_get_devices() failed with %s\n,",
+				__func__, cci_strerror(NULL, ret));
+		}
+
+		ret = cci_create_endpoint_at(devices[0], service, 0, &test->control->e, os_handle);
+	} else {
+		ret = cci_create_endpoint(NULL, 0, &test->control->e, os_handle);
+	}
+	if (ret) {
+		fprintf(stderr, "cci_create_endpoint() failed with %s (%d)\n",
+			cci_strerror(NULL, ret), ret);
+		goto out_w_cci;
+	}
+
+	ret = cci_rma_register(test->control->e, test->control->buffer, 1024*1024,
+			CCI_FLAG_WRITE, &test->control->handle);
+	check_return(test, "cci_rma_register(control->buffer)", ret, 1);
+
+	ret = cci_get_opt(test->control->e, CCI_OPT_ENDPT_URI, &test->control->uri);
+	check_return(test, "cci_get_opt", ret, 1);
+
+	fprintf(stderr, "Opened %s\n", test->control->uri);
+
+	ret = create_endpoints(test);
+	if (ret) goto out_w_ep;
+
+	if (is_server)
+		do_server(test);
+	else
+		do_client(test);
+
+    out_w_ep:
+	free(test->control->uri);
+	ret = cci_destroy_endpoint(test->control->e);
+	if (ret)
+		fprintf(stderr, "cci_destroy_endpoint() failed with %s\n",
+			cci_strerror(NULL, ret));
+
+    out_w_cci:
+	ret = cci_finalize();
+	if (ret)
+		fprintf(stderr, "cci_finalize() failed with %s\n",
+			cci_strerror(NULL, ret));
+
+    out_w_conn:
+	free(conn);
+
+    out_w_buffer:
+	free(test->control->buffer);
+
+    out_w_control:
+	free(service);
+	free(test->control);
+
+    out_w_test:
+	free(test);
+
+	return 0;
+}
-- 
2.9.3

